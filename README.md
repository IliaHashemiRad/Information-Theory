# ðŸ“¡ Information Theory & Digital Communications Assignment

> A MATLAB-based project covering core **Information Theory** and **Digital Communications** concepts, including source coding (Huffman & Lempelâ€“Ziv), entropy-rate analysis, and iterative decoding over noisy channels.

---

## âœ¨ Overview

This repository contains the implementation and report for an assignment in digital communications (taught by **Dr. Behnia**), focused on practical coding and decoding workflows.

The project includes:

- ðŸ§  **Source Coding** with custom Huffman and Lempelâ€“Ziv implementations.
- ðŸ“Š **Entropy & Efficiency Analysis** for block sources with different block lengths.
- ðŸ“¶ **Channel Decoding** using a Sum-Product style iterative decoder under a noisy BPSK setting.
- ðŸ“ A consolidated report in `Assignment1.pdf`.

---

## ðŸ—‚ï¸ Repository Structure

- `Assignment1.pdf` â€” Assignment report and documented results.
- `Q1.m` â€” Main script for Question 1 (source coding, compression ratios, dictionary cost, entropy comparison).
- `myHuffman.m` â€” Custom Huffman encoder used in Q1.
- `myLempelziv.m` â€” Custom Lempelâ€“Ziv-style encoder used in Q1.
- `Q2.m` â€” Entropy-rate and coding-efficiency analysis for grouped source symbols.
- `Q3.m` â€” BPSK simulation with iterative Sum-Product decoding and decoding accuracy evaluation.

---

## ðŸ”¬ What Each Question Covers

### 1) `Q1.m` â€” Source Coding Benchmark

- Generates a 5000-symbol synthetic English-like source using letter probabilities.
- Encodes the source with:
  - Huffman coding (`myHuffman.m`)
  - Lempelâ€“Ziv coding (`myLempelziv.m`)
- Compares:
  - âš–ï¸ Compression ratio vs fixed-length 5-bit symbol coding
  - ðŸ’¾ Dictionary storage overhead
  - ðŸ“‰ Average code length per symbol
  - ðŸ“š Source entropy reference

---

### 2) `Q2.m` â€” Block Entropy Rate & Huffman Efficiency

- Simulates a binary source (`-1`, `1`) with non-uniform probability.
- Builds grouped symbols of size `k = 1..10`.
- Computes:
  - `G_k = H(X_1, ..., X_k)/k`
  - Mean Huffman length per original symbol
  - Coding efficiency trend
- Plots all three metrics to visualize convergence behavior.

---

### 3) `Q3.m` â€” Iterative Decoding over AWGN

- Generates a random binary codeword.
- Applies BPSK modulation and additive Gaussian noise.
- Performs iterative message passing with a Sum-Product update routine.
- Reports reconstruction accuracy after fixed iterations.

---

## ðŸš€ How to Run

> Requires **MATLAB** (or a compatible environment that supports the used functions).

Run each question script independently:

```matlab
Q1
Q2
Q3
```

Expected behavior:

- `Q1`: printed compression/entropy/dictionary statistics
- `Q2`: generated plots for entropy rate, mean code length, and coding efficiency
- `Q3`: printed decoding accuracy percentage

---

## ðŸ§© Methods & Topics Demonstrated

- Entropy and source modeling
- Huffman coding (custom implementation)
- Lempelâ€“Ziv dictionary parsing and binary serialization
- Block-source analysis and coding efficiency
- BPSK over AWGN
- Iterative message passing (Sum-Product style)

---

## ðŸ“Œ Suggested GitHub â€œAboutâ€ Description

**Short professional description:**

> MATLAB implementations of information theory and digital communications algorithms: Huffman/Lempelâ€“Ziv source coding, entropy-rate analysis, and iterative BPSK decoding.

**Optional website/about tagline:**

> From source entropy to noisy-channel decoding â€” practical coding experiments in MATLAB.

---

## ðŸ‘¤ Author

- **Ilia Hashemi Rad**

---

## ðŸ“„ License

This repository is currently provided for academic and educational use. Add a formal `LICENSE` file (e.g., MIT) if you plan to distribute or reuse the code publicly.
